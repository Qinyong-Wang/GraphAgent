{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0319d217",
   "metadata": {},
   "source": [
    "# load pre-generated  node text and similar node examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e29aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "filename = '../dataset/cora_prompt.json'\n",
    "with open(filename, 'r') as f:\n",
    "    cora = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad68981",
   "metadata": {},
   "source": [
    "print one sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "533f17b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id :\n",
      "1\n",
      "\n",
      "\n",
      "lable :\n",
      "Rule_Learning\n",
      "\n",
      "\n",
      "sample_text :\n",
      "{\"id\": 1, \"title\": \" Applications of machine learning: a medical follow up study  \", \"category\": \"Masked\", \"keyword\": \"N/A\", \"author\": \" Du Junping K. L. Rasmussen J. Aagaard Brian H. Mayoh Tom Srensen \", \"affiliation\": \" Computer Science Department, Aarhus University,  Department of Obstetrics and Gynaecology, Aarhus University Hospital,  \", \"abstract\": \" This paper describes preliminary work that aims to apply some learning strategies to a medical follow-up study. An investigation of the application of three machine learning algorithms-1R, FOIL and InductH to identify risk factors that govern the colposuspension cure rate has been made. The goal of this study is to induce a generalised description or explanation of the classification attribute, colposuspension cure rate (completely cured, improved, unchanged and worse) from the 767 examples in the questionnaires. We looked for a set of rules that described which risk factors result in differences of cure rate. The results were encouraging, and indicate that machine learning can play a useful role in large scale medical problem solving. \", \"1_hop_neighbors\": [{\"id\": 344, \"title\": \" Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" ():-, . Richards and Mooney, B. Richards and R. Mooney. Towell and Shavlik, G. Towell and J. Shavlik. \"}]}\n",
      "\n",
      "\n",
      "similar_examples :\n",
      "{\"id\": 524, \"title\": \" An Inductive Learning Approach to Prognostic Prediction  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" W. Nick Street O. L. Mangasarian W. H. Wolberg \", \"affiliation\": \" Departments of Surgery and Computer Sciences University of Wisconsin  Department of Computer Sciences University of Wisconsin  Department of Surgery University of Wisconsin  \", \"abstract\": \" This paper introduces the Recurrence Surface Approximation, an inductive learning method based on linear programming that predicts recurrence times using censored training examples, that is, examples in which the available training output may be only a lower bound on the \\\"right answer.\\\" This approach is augmented with a feature selection method that chooses an appropriate feature set within the context of the linear programming generalizer. Computational results in the field of breast cancer prognosis are shown. A straightforward translation of the prediction method to an artificial neural network model is also proposed.\", \"1_hop_neighbors\": [{\"id\": 520, \"title\": \" CANCER DIAGNOSIS AND PROGNOSIS VIA LINEAR-PROGRAMMING-BASED MACHINE LEARNING  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" By W. Nick Street \"}, {\"id\": 1169, \"title\": \" Individual and Collective Prognostic Prediction  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" W. Nick Street O. L. Mangasarian W. H. Wolberg \"}, {\"id\": 1454, \"title\": \" A Neural Network Model for Prognostic Prediction  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" W. Nick Street \"}, {\"id\": 430, \"title\": \" Irrelevant Features and the Subset Selection Problem  \", \"category\": \"Theory\", \"keyword\": \"N/A\", \"author\": \" William W. Cohen Haym Hirsh, George H. John Ron Kohavi Karl Pfleger \"}]}\n",
      "\n",
      "{\"id\": 520, \"title\": \" CANCER DIAGNOSIS AND PROGNOSIS VIA LINEAR-PROGRAMMING-BASED MACHINE LEARNING  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" By W. Nick Street \", \"affiliation\": \" UNIVERSITY OF  \", \"abstract\": \"N/A\", \"1_hop_neighbors\": [{\"id\": 230, \"title\": \" Mathematical Programming in Neural Networks  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" O. L. Mangasarian \"}, {\"id\": 524, \"title\": \" An Inductive Learning Approach to Prognostic Prediction  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" W. Nick Street O. L. Mangasarian W. H. Wolberg \"}, {\"id\": 142, \"title\": \" PATTERN RECOGNITION VIA LINEAR PROGRAMMING THEORY AND APPLICATION TO MEDICAL DIAGNOSIS  \", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" O.L. MANGASARIANy, R. SETIONO AND W.H. WOLBERG \"}, {\"id\": 719, \"title\": \" Parzen. On estimation of a probability density function and mode. Annual Mathematical Statistics, 33:1065-1076, 1962.\", \"category\": \"Neural_Networks\", \"keyword\": \"N/A\", \"author\": \" [] J. Moody and C.J. Darken. [] H. Schioler and Uwe Hartman. [] M.T Musavi, W. Ahmed, K.H. Chan, K.B. Faris, and D.M. Hummels. [] P.D. Wasserman. [] H. Ritter, T. Martinetz, and Klaus Schulten. \"}, {\"id\": 478, \"title\": \" An Improved Algorithm for Incremental Induction of Decision Trees  \", \"category\": \"Case_Based\", \"keyword\": \"N/A\", \"author\": \" Paul E. Utgoff \"}]}\n",
      "\n",
      "{\"id\": 303, \"title\": \" Relating Relational Learning Algorithms  \", \"category\": \"Case_Based\", \"keyword\": \" supervised learning, representation, relational learning  \", \"author\": \" David W. Aha \", \"affiliation\": \" Turing Institute  \", \"abstract\": \" Relational learning algorithms are of special interest to members of the machine learning community; they offer practical methods for extending the representations used in algorithms that solve supervised learning tasks. Five approaches are currently being explored to address issues involved with using relational representations. This paper surveys algorithms embodying these approaches, summarizes their empirical evaluations, highlights their commonalities, and suggests potential directions for future research. \", \"1_hop_neighbors\": [{\"id\": 2091, \"title\": \" The Utility of Knowledge in Inductive Learning  Running Head: Knowledge in Inductive Learning  \", \"category\": \"Case_Based\", \"keyword\": \"N/A\", \"author\": \" Michael Pazzani Dennis Kibler \"}, {\"id\": 426, \"title\": \" Rule Induction with CN2: Some Recent Improvements  \", \"category\": \"Rule_Learning\", \"keyword\": \" learning, rule induction, CN2, Laplace, noise  \", \"author\": \" Peter Clark and Robin Boswell \"}, {\"id\": 1174, \"title\": \" LEARNING CONCEPTS BY ASKING QUESTIONS  \", \"category\": \"Theory\", \"keyword\": \"N/A\", \"author\": \" Claude Sammut Ranan B. Banerji \"}, {\"id\": 478, \"title\": \" An Improved Algorithm for Incremental Induction of Decision Trees  \", \"category\": \"Case_Based\", \"keyword\": \"N/A\", \"author\": \" Paul E. Utgoff \"}]}\n",
      "\n",
      "{\"id\": 2070, \"title\": \" A Partial Memory Incremental Learning Methodology And Its Application To Computer Intrusion Detection  \", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" Marcus A. Maloof and Ryszard S. Michalski \", \"affiliation\": \"N/A\", \"abstract\": \"N/A\", \"1_hop_neighbors\": [{\"id\": 2640, \"title\": \" Learning Evolving Concepts Using Partial-Memory Approach  Machine Learning and Inference Laboratory  \", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" Marcus A. Maloof and Ryszard S. Michalski* George Mason \"}, {\"id\": 2602, \"title\": \" A Method for Partial-Memory Incremental Learning and its Application to Computer Intrusion Detection Machine Learning\", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" Marcus A. Maloof Ryszard S. Michalski \"}]}\n",
      "\n",
      "{\"id\": 2339, \"title\": \" An intelligent search method using Inductive Logic Programming  \", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" Nobuhiro Inuzuka, Hirohisa Seki and Hidenori Itoh \", \"affiliation\": \" Department of Intelligence and Computer Science Nagoya Institute of Technology  \", \"abstract\": \" We propose a method to use Inductive Logic Programming to give heuristic functions for searching goals to solve problems. The method takes solutions of a problem or a history of search and a set of background knowledge on the problem. In a large class of problems, a problem is described as a set of states and a set of operators, and is solved by finding a series of operators. A solution, a series of operators that brings an initial state to a final state, is transformed into positive and negative examples of a relation \\\"better-choice\\\", which describes that an operator is better than others in a state. We also give a way to use the \\\"better-choice\\\" relation as a heuristic function. The method can use any logic program as background knowledge to induce heuristics, and induced heuristics has high readability. The paper inspects the method by applying to a puzzle.\", \"1_hop_neighbors\": [{\"id\": 344, \"title\": \" Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" ():-, . Richards and Mooney, B. Richards and R. Mooney. Towell and Shavlik, G. Towell and J. Shavlik. \"}, {\"id\": 675, \"title\": \" Combining FOIL and EBG to Speed-up Logic Programs  \", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" John M. Zelle and Raymond J. Mooney \"}, {\"id\": 2126, \"title\": \" Applying ILP to Diterpene Structure Elucidation from 13 C NMR Spectra  \", \"category\": \"Rule_Learning\", \"keyword\": \"N/A\", \"author\": \" Saso Dzeroski (;) Steffen Schulze-Kremer () Karsten R. Heidtke () Karsten Siems () Dietrich Wettschereck () \"}]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in cora[\"1\"]:\n",
    "    print(key, \":\")\n",
    "    print(cora[\"1\"][key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a98ed9",
   "metadata": {},
   "source": [
    "# Sample around 20% of nodes from the full dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3dd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_keys = random.sample(list(cora.keys()), 550)\n",
    "sampled_cora = {key: cora[key] for key in sampled_keys}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04255705",
   "metadata": {},
   "source": [
    "# Inference\n",
    "insert your openai.api_key\n",
    "or you can revise the get_completion funtion so that you can use other LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7131a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "#model=\"gpt-3.5-turbo-16k\" \n",
    "#model=\"gpt-4\" \n",
    "model=\"gpt-4-1106-preview\"\n",
    "openai.organization = \"\"\n",
    "openai.api_key = \"\"\n",
    "s\n",
    "def get_completion(prompt, model=model):    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.1, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1252865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inductive_prompt(similar_examples):\n",
    "    \n",
    "    prompt = similar_examples\n",
    "    prompt += \"\\n\"\n",
    "    prompt += f\"\"\"\n",
    "        You are a machine learning expert. For the given example and your own knowledges. \n",
    "        Can you find some reasons that why each paper falls into its category. Only briefly list the reasons\n",
    "        \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_deductive_prompt(sample_text, similar_examples, reasons):\n",
    "    prompt = \"Examples: \\n\"\n",
    "    prompt += similar_examples\n",
    "    prompt += \"Reasons: \\n\"\n",
    "    prompt += reasons\n",
    "    prompt += \"\\n\"\n",
    "    prompt += \"Target Paper: \\n\"\n",
    "    prompt += sample_text + \"\\n\"\n",
    "    prompt += \"\"\"\n",
    "    the \"Target Paper\" should be in one of which category blow?\n",
    "    1: 'Case_Based',\n",
    "    2:'Genetic_Algorithms',\n",
    "    3.'Neural_Networks',\n",
    "    4.'Probabilistic_Methods',\n",
    "    5.'Reinforcement_Learning',\n",
    "    6.'Rule_Learning',\n",
    "    7.'Theory'\n",
    "        \n",
    "        \n",
    "    Based on the reasons and examples, think step by step and print reasoning process, \n",
    "    then choose the category name.\n",
    "    output all prediction and reasoning in json format:\n",
    "    {\n",
    "        reasoning:, \n",
    "        prediction: \n",
    "    }\n",
    "    \"\"\"\n",
    "    prompt += '\\n'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1adeac5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tp = 0\n",
    "verbose = False\n",
    "data = sampled_cora\n",
    "\n",
    "for idx in data:\n",
    "    print(\"reasoning on sample:\" , idx)\n",
    "    sample = data[idx]\n",
    "    similar_examples = sample[\"similar_examples\"]\n",
    "    \n",
    "    inductive_prompt = get_inductive_prompt(similar_examples)\n",
    "    reasons = get_completion(inductive_prompt)\n",
    "    sample_text = sample[\"sample_text\"]\n",
    "    deductive_prompt = get_deductive_prompt(sample_text, similar_examples, reasons)\n",
    "    res = get_completion(deductive_prompt)\n",
    "\n",
    "    \n",
    "    if model == \"gpt-4-1106-preview\":\n",
    "        start = res.find(\"json\") + len(\"json\")\n",
    "        end = res.find(\"```\", start)\n",
    "        json_string = res[start:end].strip()\n",
    "        res_dict = json.loads(json_string)\n",
    "    elif model == \"gpt-4\":\n",
    "        start = res.find(\"{\") - 1\n",
    "        end = res.find(\"}\", start) + 1\n",
    "        json_string = res[start:end].strip()\n",
    "        res_dict = json.loads(json_string)\n",
    "    else: \n",
    "        json_string = json.loads(res)\n",
    "    \n",
    "    if verbose:\n",
    "        #print(\"similar_examples: \\n\", similar_examples, \"\\n\")\n",
    "        #print(\"reasons: \\n\", reasons, \"\\n\")\n",
    "        print(\"deductive_prompt: \\n\",deductive_prompt, \"\\n\")\n",
    "        print(\"result: \\n\", res, \"\\n\")\n",
    "        print(\"json_result: \\n\", res_dict, \"\\n\")\n",
    "        print(\"lable:\", sample[\"lable\"],\"\\n\")\n",
    "        print(\"===========================================\")\n",
    "    \n",
    "    if res_dict[\"prediction\"] == sample[\"lable\"]:\n",
    "        tp += 1\n",
    "    cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f5d2e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676d3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
